# -*- coding: utf-8 -*-
"""Credit_card_fraud_det.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x--wElIfk1558htsjIWqF2smKccCXFNp

# Getting started
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from imblearn.pipeline import Pipeline as ImbPipeline # Use imblearn's pipeline for samplers

df = pd.read_csv('creditcard.csv')

df.head()

df.info()

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

"""# *Exploratory Data Analysis*"""

sns.countplot(x='Class',data=df)
plt.title('Class Distribution (0: Legitimate, 1: Fraud)')
plt.show()

print(df['Class'].value_counts())

fig, ax = plt.subplots(1, 2, figsize=(15, 5))
sns.histplot(df['Time'], bins=50, ax=ax[0], kde=True)
sns.histplot(df['Amount'], bins=50, ax=ax[1], kde=True)
plt.suptitle('Distribution of Time and Amount Features')
plt.show()

sns.boxplot(x='Class',y='Amount', data=df)
plt.title('Amount Distribution by Class')
# plt.ylim(0, 2000) # Limit y-axis for better visualization of lower amounts
plt.show()

# Select a subset of V features for heatmap if full matrix is too large
# Or just plot correlation with 'Class'
correlation_matrix = df.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)
plt.title('Correlation Matrix of Features')
plt.show()
print(df.corr()['Class'].sort_values(ascending=False)) # Correlation with target

# Drop Time if not relevant, otherwise scale it. Often Time is dropped or binned.
# df = df.drop('Time', axis=1) # Example if dropping Time

# Separate features (X) and target (y)
X = df.drop('Class', axis=1)
y = df['Class']

# Scale 'Amount' and 'Time'
scaler = StandardScaler() # Or RobustScaler()
X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1, 1))
X['Time'] = scaler.fit_transform(X['Time'].values.reshape(-1, 1))

# Split data AFTER scaling (important to prevent data leakage)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""#  Model Building & Imbalance Handling Strategies"""

rf_baseline = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') # Use class_weight for RF
rf_baseline.fit(X_train, y_train) #training the model
y_pred_baseline = rf_baseline.predict(X_test)
print("Random Forest Baseline (Imbalanced Data):")
print(classification_report(y_test, y_pred_baseline))

cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# Example for SMOTE + Random Forest within a pipeline for CV
pipeline_smote_rf = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(random_state=42))
])
# Scores will be calculated using cross_val_score or GridSearchCV with this pipeline

"""# **Applying Different Models & Evaluation**"""

pipeline_lr_smote = ImbPipeline([('smote', SMOTE(random_state=42)), ('lr', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'))])
pipeline_lr_nm = ImbPipeline([('nm', NearMiss(version=1)), ('lr', LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'))])

# Evaluate using cross-validation (e.g., ROC AUC)
# scores_lr_smote = cross_val_score(pipeline_lr_smote, X_train, y_train, cv=cv_strategy, scoring='roc_auc')
# print(f"LR + SMOTE CV AUC: {np.mean(scores_lr_smote):.4f}")

# Fit and predict on test set for full metrics
pipeline_lr_smote.fit(X_train, y_train)
y_pred_lr_smote = pipeline_lr_smote.predict(X_test)
print("\nLogistic Regression + SMOTE:")
print(classification_report(y_test, y_pred_lr_smote))
# ... Similar for NearMiss

pipeline_rf_smote = ImbPipeline([('smote', SMOTE(random_state=42)), ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))])
pipeline_rf_nm = ImbPipeline([('nm', NearMiss(version=1)), ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))])

pipeline_rf_smote.fit(X_train, y_train)
y_pred_rf_smote = pipeline_rf_smote.predict(X_test)
print("\nRandom Forest + SMOTE:")
print(classification_report(y_test, y_pred_rf_smote))
# ... Similar for NearMiss

# Example for SVC (might take a long time)
# pipeline_svc_smote = ImbPipeline([('smote', SMOTE(random_state=42)), ('svc', SVC(random_state=42, probability=True, class_weight='balanced'))])
# pipeline_svc_smote.fit(X_train, y_train)
# y_pred_svc_smote = pipeline_svc_smote.predict(X_test)
# print("\nSVC + SMOTE:")
# print(classification_report(y_test, y_pred_svc_smote))

# Example for Decision Tree
pipeline_dt_smote = ImbPipeline([('smote', SMOTE(random_state=42)), ('dt', DecisionTreeClassifier(random_state=42, class_weight='balanced'))])
pipeline_dt_smote.fit(X_train, y_train)
y_pred_dt_smote = pipeline_dt_smote.predict(X_test)
print("\nDecision Tree + SMOTE:")
print(classification_report(y_test, y_pred_dt_smote))

# Example for kNN (ensure data is scaled if not done globally)
pipeline_knn_smote = ImbPipeline([('smote', SMOTE(random_state=42)), ('knn', KNeighborsClassifier(n_neighbors=5))])
pipeline_knn_smote.fit(X_train, y_train)
y_pred_knn_smote = pipeline_knn_smote.predict(X_test)
print("\nK-Nearest Neighbour + SMOTE:")
print(classification_report(y_test, y_pred_knn_smote))



"""### Simple Prediction and Probability Example"""

# Select the model you want to inspect (e.g., lr_balanced, rf_balanced, dt_balanced, knn)
# Make sure the chosen model has been trained in the previous steps.
model = pipeline_lr_smote  # Example: Using Logistic Regression

# Get predictions
try:
    y_pred = model.predict(X_test)
    print("Predictions (first 10):", y_pred[:10])

    # Get predicted probabilities if available
    if hasattr(model, 'predict_proba'):
        y_proba = model.predict_proba(X_test)
        print("Predicted Probabilities (first 10):")
        print(y_proba[:10])
    else:
        print("predict_proba not available for this model.")

except NameError:
    print("The selected model is not found. Please ensure it was trained.")
except NotFittedError:
    print("The selected model is not fitted. Please ensure it was trained.")

model = pipeline_rf_smote # Example: Using Logistic Regression

# Get predictions
try:
    y_pred = model.predict(X_test)
    print("Predictions (first 10):", y_pred[:10])

    # Get predicted probabilities if available
    if hasattr(model, 'predict_proba'):
        y_proba = model.predict_proba(X_test)
        print("Predicted Probabilities (first 10):")
        print(y_proba[:10])
    else:
        print("predict_proba not available for this model.")

except NameError:
    print("The selected model is not found. Please ensure it was trained.")
except NotFittedError:
    print("The selected model is not fitted. Please ensure it was trained.")

model = pipeline_dt_smote # Example: Using Logistic Regression

# Get predictions
try:
    y_pred = model.predict(X_test)
    print("Predictions (first 10):", y_pred[:10])

    # Get predicted probabilities if available
    if hasattr(model, 'predict_proba'):
        y_proba = model.predict_proba(X_test)
        print("Predicted Probabilities (first 10):")
        print(y_proba[:10])
    else:
        print("predict_proba not available for this model.")

except NameError:
    print("The selected model is not found. Please ensure it was trained.")
except NotFittedError:
    print("The selected model is not fitted. Please ensure it was trained.")



model = pipeline_knn_smote # Example: Using Logistic Regression

# Get predictions
try:
    y_pred = model.predict(X_test)
    print("Predictions (first 10):", y_pred[:10])

    # Get predicted probabilities if available
    if hasattr(model, 'predict_proba'):
        y_proba = model.predict_proba(X_test)
        print("Predicted Probabilities (first 10):")
        print(y_proba[:10])
    else:
        print("predict_proba not available for this model.")

except NameError:
    print("The selected model is not found. Please ensure it was trained.")
except NotFittedError:
    print("The selected model is not fitted. Please ensure it was trained.")



"""### Classification Reports for Trained Models"""

from sklearn.metrics import classification_report

# Assuming the models lr_balanced, rf_balanced, dt_balanced, and knn are fitted and available.

# --- Logistic Regression ---
print("--- Logistic Regression ---")
try:
    y_pred_lr = pipeline_lr_smote.predict(X_test)
    print(classification_report(y_test, y_pred_lr))
except NameError:
    print("Logistic Regression model (lr_balanced) not found. Please ensure it was trained.")
except NotFittedError:
    print("Logistic Regression model (lr_balanced) is not fitted. Please ensure it was trained.")

print("-" * 25)

# --- Random Forest ---
print("--- Random Forest ---")
try:
    y_pred_rf = pipeline_rf_smote.predict(X_test)
    print(classification_report(y_test, y_pred_rf))
except NameError:
    print("Random Forest model (rf_balanced) not found. Please ensure it was trained.")
except NotFittedError:
    print("Random Forest model (rf_balanced) is not fitted. Please ensure it was trained.")

print("-" * 25)

# --- Decision Tree ---
print("--- Decision Tree ---")
try:
    y_pred_dt = pipeline_dt_smote.predict(X_test)
    print(classification_report(y_test, y_pred_dt))
except NameError:
    print("Decision Tree model (dt_balanced) not found. Please ensure it was trained.")
except NotFittedError:
    print("Decision Tree model (dt_balanced) is not fitted. Please ensure it was trained.")

print("-" * 25)

# --- K-Nearest Neighbour ---
print("--- K-Nearest Neighbour ---")
try:
    y_pred_knn = pipeline_knn_smote.predict(X_test)
    print(classification_report(y_test, y_pred_knn))
except NameError:
    print("K-Nearest Neighbour model (knn) not found. Please ensure it was trained.")
except NotFittedError:
    print("K-Nearest Neighbour model (knn) is not fitted. Please ensure it was trained.")

print("-" * 25)

# Assuming you have y_test and y_proba for different models
# For RF + SMOTE:
y_proba_rf_smote = pipeline_rf_smote.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf_smote)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'RF + SMOTE (AUC = {roc_auc_rf:.2f})')

print(" ")

y_proba_lr_smote = pipeline_lr_smote.predict_proba(X_test)[:, 1]
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr_smote)
roc_auc_lr = auc(fpr_lr, tpr_lr)

plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, color='darkorange', lw=2, label=f'LR + SMOTE (AUC = {roc_auc_lr:.2f})')

print(" ")

y_proba_dt_smote = pipeline_dt_smote.predict_proba(X_test)[:, 1]
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_proba_dt_smote)
roc_auc_dt = auc(fpr_dt, tpr_dt)

plt.figure(figsize=(8, 6))
plt.plot(fpr_dt, tpr_dt, color='darkorange', lw=2, label=f'DT + SMOTE (AUC = {roc_auc_dt:.2f})')

print(" ")

y_proba_knn_smote = pipeline_knn_smote.predict_proba(X_test)[:, 1]
fpr_knn, tpr_knn, _ = roc_curve(y_test, y_proba_knn_smote)
roc_auc_knn = auc(fpr_knn, tpr_knn)

plt.figure(figsize=(8, 6))
plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label=f'KNN + SMOTE (AUC = {roc_auc_knn:.2f})')

# Add other models here
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

def plot_learning_curve(estimator, title, X, y, cv, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):
    plt.figure(figsize=(10, 6))
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("Score (F1-score for fraud)")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1'
    )
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")
    plt.legend(loc="best")
    plt.show()

#  RF + SMOTE
plot_learning_curve(pipeline_rf_smote, "Learning Curve (Random Forest + SMOTE)",
                    X_train, y_train, cv=cv_strategy)

plot_learning_curve(pipeline_dt_smote, "Learning Curve (Decision Tree + SMOTE)",
                    X_train, y_train, cv=cv_strategy)

plot_learning_curve(pipeline_lr_smote, "Learning Curve (Logistic Regression+ SMOTE)",
                    X_train, y_train, cv=cv_strategy)

plot_learning_curve(pipeline_knn_smote, "Learning Curve (KNN + SMOTE)",
                    X_train, y_train, cv=cv_strategy)

